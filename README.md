# cvpaper.challenge-summary
コンピュータビジョン研究コミュニティcvpaper.challengeのサマリ。サーベイ資料や研究成果などへのリンクをまとめます。研究メンバーへの参加希望は[こちら](http://xpaperchallenge.org/cv/recruit/)をご確認ください。

## Table of contents

* [HP](#hp)
* [研究機関](#研究機関)
* [研究成果](#研究成果)
* [データセット](#データセット)
* [研究グループ](#研究グループ)
* [網羅的サーベイ](#網羅的サーベイ)
* [メタサーベイ](#メタサーベイ)
* [会議レポート](#会議レポート)
* [招待講演](#招待講演)
* [記事](#記事)
* [その他](#その他)

## HP

* [メインページ](http://xpaperchallenge.org/cv/)
* [旧サイト](https://sites.google.com/site/cvpaperchallenge/home)
* [メンバー募集](http://xpaperchallenge.org/cv/recruit/)
* [Twitter](https://twitter.com/CVpaperChalleng)
* [SlideShare](https://www.slideshare.net/cvpaperchallenge/)
* [GitHub](https://github.com/cvpaperchallenge)
* [論文ナビ](https://rnavi.org/members/cvpaper-challenge/)


## 研究機関

* 筑波大学 ヒューマンセンタードビジョン研究室（佐藤研究室）[[Link]](https://staff.aist.go.jp/yu.satou/univ.htm)
* 早稲田大学 森島研究室 [[Link]](http://www.mlab.phys.waseda.ac.jp/)
* 慶應義塾大学 青木研究室 [[Link]](https://aoki-medialab.jp/)
* 東京電機大学 中村研究室 [[Link]](http://www.is.fr.dendai.ac.jp/)
* 東京工業大学 井上研究室 [[Link]](https://mmai.tech/)
* nlpaper.challenge [[Link]](http://xpaperchallenge.org/nlp/)
* robotpaper.challenge [[Link]](https://sites.google.com/view/robotpaperchallenge)
* AI-SCHOLAR [[Link]](https://ai-scholar.tech/)

## 研究成果

* 2021
	* Yuchi Ishikawa, Seito Kasai, Yoshimitsu Aoki, Hirokatsu Kataoka, "Alleviating Over-segmentation Errors by Detecting Action Boundaries," Winter Conference on Applications of Computer Vision (WACV), 2021. (arXiv pre-print:2007.06866) [[Project]](https://yiskw713.github.io/asrf/) [[PDF]](https://arxiv.org/abs/2007.06866) [[GitHub]](https://github.com/yiskw713/asrf)
	* Hiroaki Aizawa, Hirokatsu Kataoka, Yutaka Satoh, Kunihito Kato, "Viewpoint-agnostic Image Rendering," Winter Conference on Applications of Computer Vision (WACV), 2021. [[Project]](https://aizawan.github.io/vair/) [[PDF]](https://openaccess.thecvf.com/content/WACV2021/html/Aizawa_Viewpoint-Agnostic_Image_Rendering_WACV_2021_paper.html)
* 2020
	* Hirokatsu Kataoka, Kazushige Okayasu, Asato Matsumoto, Eisuke Yamagata, Ryosuke Yamada, Nakamasa Inoue, Akio Nakamura, Yutaka Satoh, “Pre-training without Natural Images”, Asian Conference on Computer Vision (ACCV), 2020. [[Project]](https://hirokatsukataoka16.github.io/Pretraining-without-Natural-Images/) [[PDF]](https://openaccess.thecvf.com/content/ACCV2020/papers/Kataoka_Pre-training_without_Natural_Images_ACCV_2020_paper.pdf) [[Code]](https://github.com/hirokatsukataoka16/FractalDB) [[Dataset]](https://hirokatsukataoka16.github.io/Pretraining-without-Natural-Images/#dataset) [[Oral]](http://hirokatsukataoka.net/pdf/accv20_kataoka_oral.pdf) [[Poster]](http://hirokatsukataoka.net/pdf/accv20_kataoka_poster.pdf) [[Video]](https://www.youtube.com/watch?v=d-NagM4nGIQ) (Best Paper Honorable Mention Award; Oral Presentation; 3 Strong Accepts) 
	* Yue Qiu, Yutaka Satoh, Ryota Suzuki, Kenji Iwata, Hirokatsu Kataoka, "3D-Aware Scene Change Captioning from Multiview Images," IEEE Robotics and Automation Letters (RA-L) with IROS presentation, 2020.
	* Nakamasa Inoue*, Eisuke Yamagata*, Hirokatsu Kataoka, "Initialization Using Perlin Noise for Training Networks with a Limited Amount of Data," International Conference on Pattern Recognition (ICPR), 2020. (* indicates equal contribution) [[PDF]](https://arxiv.org/abs/2101.07406)
	* Takehiko Ohkawa, Naoto Inoue, Hirokatsu Kataoka, Nakamasa Inoue, “Augmented Cyclic Consistency Regularization for Unpaired Image-to-Image Translation”, International Conference on Pattern Recognition (ICPR), 2020. (arXiv pre-print:2003.00187) [[PDF]](https://arxiv.org/abs/2003.00187)
	* Hideki Tsunashima, Shigeo Morishima, Junji Yamato, Qiu Chen, Hirokatsu Kataoka, “Adversarial Knowledge Distillation for a Compact Generator”, International Conference on Pattern Recognition (ICPR), 2020.
	* Hiroaki Aizawa, Hirokatsu Kataoka, Yutaka Satoh, Kunihito Kato, "Disentangle, Assemble, and Synthesize: Unsupervised Learning to Disentangle Appearance and Location," International Conference on Pattern Recognition (ICPR), 2020. [[Project]](https://aizawan.github.io/das/)
	* Seito Kasai, Yuchi Ishikawa, Masaki Hayashi, Yoshimitsu Aoki, Kensho Hara, Hirokatsu Kataoka, "Retrieving and Highlighting Action with Spatiotemporal Reference," IEEE International Conference on Image Processing (ICIP), 2020. [[PDF]](https://arxiv.org/abs/2005.09183)
	* Hirokatsu Kataoka, Tenga Wakamiya, Kensho Hara, Yutaka Satoh, "Would Mega-scale Datasets Further Enhance Spatiotemporal 3D CNNs?", arXiv pre-print:2004.04968, 2020. [[PDF]](https://arxiv.org/abs/2004.04968) [[GitHub]](https://github.com/kenshohara/3D-ResNets-PyTorch)
	* Munetaka Minoguchi, Ken Okayama, Yutaka Satoh, Hirokatsu Kataoka, "Weakly Supervised Dataset Collection for Robust Person Detection", arXiv pre-print:2003.12263, 2020. [[PDF]](https://arxiv.org/abs/2003.12263) [[GitHub]](https://github.com/cvpaperchallenge/FashionCultureDataBase_DLoader)
	* Hirokatsu Kataoka, Teppei Suzuki, Kodai Nakashima, Yutaka Satoh, Yoshimitsu Aoki, "Joint Pedestrian Detection and Risk-level Prediction with Motion-Representation-by-Detection", International Conference on Robotics and Automation (ICRA), 2020. [[PDF]](http://hirokatsukataoka.net/pdf/icra20_kataoka_jointdetection.pdf) (Acceptance rate: 42.0%; 1st place in Robotics at Google Scholar Metrics)
	* Ryota Suzuki, Kota Yoshida, Munetaka Minoguchi, Kazuki Tsubura, Takumu Ikeya, Akio Nakamura, Hirokatsu Kataoka, "Joking AI via Visual Cues", Human Computer Interaction International 2020.
* 2019
	* Takahiro Itazuri, Yoshihiro Fukuhara, Hirokatsu Kataoka, Shigeo Morishima, "What Do Adversarially Robust Models Look At?", arXiv pre-print:1905.07666, 2019. [[PDF]](https://arxiv.org/abs/1905.07666)
	* Yue Qiu, Yutaka Satoh, Hirokatsu Kataoka, Ryota Suzuki, "Incorporating Depth into Visual Question Answering", CVPR 2019 Workshop on Visual Question Answering and Dialog, 2019.
	* Yue Qiu, Yutaka Satoh, Hirokatsu Kataoka, Ryota Suzuki, "Visual Question Answering with RGB-D Images", CVPR 2019 Workshop on Women in Computer Vision (WiCV), 2019.
	* Hirokatsu Kataoka, Kaori Abe, Munetaka Minoguchi, Akio Nakamura, Yutaka Satoh, "Ten-million-order Human Database for World-wide Fashion Culture Analysis", CVPR 2019 Workshop on Understanding Subjective Attributes of Data, Focus on Fashion and Subjective Search (FFSS-USAD). (Oral) [[PDF]](http://openaccess.thecvf.com/content_CVPRW_2019/papers/FFSS-USAD/Kataoka_Ten-Million-Order_Human_Database_for_World-Wide_Fashion_Culture_Analysis_CVPRW_2019_paper.pdf) [[Oral]](http://hirokatsukataoka.net/pdf/cvprw19_kataoka_fcdb_oral.pdf) [[Poster]](http://hirokatsukataoka.net/pdf/cvprw19_kataoka_fcdb_poster.pdf) [[GitHub]](https://github.com/cvpaperchallenge/FashionCultureDataBase_DLoader)
	* Hirokatsu Kataoka, Yutaka Satoh, "Unsupervised Out-of-context Action Understanding", IEEE International Conference on Robotics and Automation (ICRA), 2019. (Acceptance rate: 44.0%; 1st place in Robotics at Google Scholar Metrics)
* 2018
	* Naofumi Akimoto, Hirokatsu Kataoka, Yoshimitsu Aoki, "Generating Effect Animation with Conditional GANs", SIGGRAPH Asia 2018 Posters, 2018. [[Video]](https://www.youtube.com/watch?v=ODzBcwvBZjk)
	* Shintaro Yamamoto, Yoshihiro Fukuhara, Ryota Suzuki, Shigeo Morishima, Hirokatsu Kataoka, "Automatic Paper Summary Generation from Visual and Textual Information", International Conference on Machine Vision (ICMV) 2018
	* Kaori Abe, Munetaka Minoguchi, Teppei Suzuki, Tomoyuki Suzuki, Naofumi Akimoto, Yue Qiu, Ryota Suzuki, Kenji Iwata, Yutaka Satoh, Hirokatsu Kataoka, "Fashion Culture Database: Construction of Database for World-wide Fashion Analysis", IEEE ICARCV 2018. [[PDF]](https://arxiv.org/abs/1703.07920)
	* Tomoyuki Suzuki, Munetaka Minoguchi, Ryota Suzuki, Akio Nakamura, Kenji Iwata, Yutaka Satoh, Hirokatsu Kataoka, "Semantic Change Detection", IEEE ICARCV 2018. [[PDF]](http://arxiv.org/abs/1604.07513)
	* Tomoyuki Suzuki, Takahiro Itazuri, Kensho Hara, Hirokatsu Kataoka, "Learning Spatiotemporal 3D Convolution with Video Order Self-Supervision", ECCV 2018 Workshop on Person in Context (PIC).
	* Ryota Natsume*, Kazuki Inoue*, Shintaro Yamamoto, Yoshihiro Fukuhara, Shigeo Morishima, Hirokatsu Kataoka, "Understanding Fake-Faces", ECCV 2018 Workshop on Brain-Driven Computer Vision (BDCV), 2018. [[PDF]](https://arxiv.org/abs/1809.08391)
	* Kensho Hara, Hirokatsu Kataoka, Yutaka Satoh, "Towards Good Practice for Action Recognition with Spatiotemporal 3D Convolutions", International Conference on Pattern Recognition (ICPR), 2018.
	* Hirokatsu Kataoka Shuhei Ohki, Kenji Iwata, Yutaka Satoh, "Occlusion Handling Human Detection with Refocused Images", International Conference on Pattern Recognition (ICPR), 2018. [[PDF]](http://hirokatsukataoka.net/pdf/icpr18_kataoka_refocus.pdf)
	* Kensho Hara, Hirokatsu Kataoka, Yutaka Satoh, "AIST Submission to ActivityNet Challenge 2018", ActivityNet Large Scale Activity Recognition Challenge in Conjunction with CVPR 2018. [[PDF]](http://hirokatsukataoka.net/pdf/cvprw18_hara_activitynetchallenge.pdf)
	* Tenga Wakamiya, Takumu Ikeya, Akio Nakamura, Kensho Hara, Hirokatsu Kataoka, "TDU&AIST Submission for ActivityNet Challenge 2018 in Video Caption Task", ActivityNet Large Scale Activity Recognition Challenge in Conjunction with CVPR 2018. [[PDF]](http://hirokatsukataoka.net/pdf/cvprw18_wakamiya&ikeya_activitynetchallenge.pdf)
	* Yue Qiu, Fangge Chen, Shuhei Oki, Hirokatsu Kataoka, “Image generation associated with music data”, CVPR 2018 Workshop on Sight and Sound (WSS). [[PDF]](http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w49/Qiu_Image_Generation_Associated_CVPR_2018_paper.pdf)
	* Kota Yoshida, Munetaka Minoguchi, Kenichiro Wani, Akio Nakamura, Hirokatsu Kataoka, "Neural Joking Machine: An image captioning for a humor", CVPR 2018 Language and Vision Workshop. [[PDF]](https://arxiv.org/pdf/1805.11850.pdf) [[Oral]](http://hirokatsukataoka.net/research/neuraljokingmachine/cvprw18_njm_oral.pdf) [[Poster]](http://hirokatsukataoka.net/research/neuraljokingmachine/cvprw18_njm_poster.pdf)
	* Kensho Hara, Hirokatsu Kataoka, Yutaka Satoh, "Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?", IEEE/CVF International Conference on Computer Vision and Pattern Recognition (CVPR), 2018. [[PDF]](https://arxiv.org/abs/1711.09577v2) [[Poster]](http://hirokatsukataoka.net/research/3dconv/cvpr18_3dconv_poster.pdf) [GitHub](https://github.com/kenshohara/3D-ResNets-PyTorch) (Acceptance rate: 29.6%; 1st place in Computer Vision at Google Scholar Metrics)
	* Tomoyuki Suzuki*, Hirokatsu Kataoka*, Yoshimitsu Aoki, Yutaka Satoh, "Anticipating Traffic Accidents with Adaptive Loss and Large-scale Incident DB", IEEE/CVF International Conference on Computer Vision and Pattern Recognition (CVPR), 2018. [[PDF]](https://arxiv.org/abs/1804.02675) [[Poster]](http://hirokatsukataoka.net/research/nidb/cvpr18_anticipation_poster.pdf) (Acceptance rate: 29.6%; 1st place in Computer Vision at Google Scholar Metrics; * indicates equal contribution)
	* Hirokatsu Kataoka, Yutaka Satoh, Yoshimitsu Aoki, Shoko Oikawa, Yasuhiro Matsui, "Temporal and Fine-grained Pedestrian Action Recognition on Driving Recorder Database", Sensors, 2018. [[PDF]](http://www.mdpi.com/1424-8220/18/2/627) (Impact Factor: 2.67)
	* Hirokatsu Kataoka, Teppei Suzuki, Shoko Oikawa, Yasuhiro Matsui, Yutaka Satoh, "Drive Video Analysis for the Detection of Traffic Near-Miss Incidents", IEEE International Conference on Robotics and Automation (ICRA), May 2018. [[PDF]](https://arxiv.org/abs/1804.02555) [[Poster]](http://hirokatsukataoka.net/research/nidb/icra18_kataoka_nidb_poster.pdf) [[Digest]](http://hirokatsukataoka.net/research/nidb/icra18_kataoka_nidb_digest.pdf) (Acceptance rate: 40.6%; 1st place in Robotics at Google Scholar Metrics)
* 2017
	* Kensho Hara, Hirokatsu Kataoka, Yutaka Satoh, "Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition", ICCV 2017 Workshop on ChaLearn Looking at People, Oct. 2017. [[PDF]](https://arxiv.org/abs/1708.07632) [[GitHub]](https://github.com/kenshohara/3D-ResNets-PyTorch)
	* Kaori Abe*, Teppei Suzuki*, Shunya Ueta, Akio Nakamura, Yutaka Satoh, Hirokatsu Kataoka, "Dynamic Fashion Cultures", arXiv pre-print:1703.07920, 2017. (* indicates equal contribution) [[PDF]](https://arxiv.org/abs/1703.07920) [[Poster]](http://www.hirokatsukataoka.net/research/dynamicfashioncultures/dynamicfashioncultures.pdf) [Presen](http://www.hirokatsukataoka.net/research/dynamicfashioncultures/dynamicfashioncultures_presen.pdf) (Acceptance rate (oral): 28.0%, Best Student Award)
	* Hirokatsu Kataoka, Soma Shirakabe, Yun He, Shunya Ueta, Teppei Suzuki, Kaori Abe, Asako Kanezaki, Shin'ichiro Morita, Toshiyuki Yabe, Yoshihiro Kanehara, Hiroya Yatsuyanagi, Shinya Maruyama, Ryosuke Takasawa, Masataka Fuchida, Yudai Miyashita, Kazushige Okayasu, Yuta Matsuzaki, "cvpaper.challenge in 2016: Futuristic Computer Vision through 1,600 Papers Survey", arXiv pre-print, 1707.06436, Jul. 2017. [[PDF]](https://arxiv.org/abs/1707.06436) [[PDF2]](http://www.hirokatsukataoka.net/pdf/arxiv17_kataoka_cvpaperchallenge.pdf)
	* Yuta Matsuzaki, Kazushige Okayasu, Akio Nakamura, Hirokatsu Kataoka, "Generated Motion Maps", CVPR 2017 Workshop on Brave New Ideas for Motion Representations in Videos (BNMW), Jul. 2017. [[PDF]](https://openreview.net/pdf?id=S1ybBMw-W)
	* Yue Qiu, Yutaka Satoh, Ryota Suzuki, Hirokatsu Kataoka, "Sensing and recognition of typical indoor family scenes using an RGB-D camera", CVPR 2017 Workshop, WiCV, Jul. 2017.
	* Kaori Abe, Hirokatsu Kataoka, Akio Nakamura, "Weighted Feature Integration for Person Re-identification", CVPR 2017 Workshop, WiCV, Jul. 2017.
	* Hirokatsu Kataoka, Kaori Abe, Akio Nakamura, Yutaka Satoh, "Collaborative Descriptors: Convolutional Maps for Preprocessing", arXiv pre-print:1705.03595, May 2017. [[PDF]](https://arxiv.org/abs/1705.03595)
	* Yuta Matsuzaki*, Kazushige Okayasu*, Takaaki Imanari, Naomichi Kobayashi, Yoshihiro Kanehara, Ryousuke Takasawa, Akio Nakamura, Hirokatsu Kataoka, "Could you guess an interesting movie from the posters?: An evaluation of vision-based features on movie poster database", IAPR Conference on Machine Vision Applications (MVA2017), May 2017. (* equal contribution) [[PDF]](https://arxiv.org/abs/1704.02199) [[Poster]](http://hirokatsukataoka.net/research/oscar/mva2017_oscar_poster.pdf)
	* Teppei Suzuki, Yoshimitsu Aoki, Hirokatsu Kataoka, "Pedestrian Near-Miss Analysis on Vehicle-Mounted Driving Recorders", IAPR Conference on Machine Vision Applications (MVA2017), May 2017.
	* Yudai Miyashita, Hirokatsu Kataoka, Akio Nakamura, "Analyzing Fine Motion Considering Individual Habits for Appearance-based Proficiency Evaluation", IEICE Transactions on Information and Systems, vol.E100-D, no.1, Jan. 2017. [[PDF]](https://www.jstage.jst.go.jp/article/transinf/E100.D/1/E100.D_2016EDP7138/_article)
* 2016
	* Yun He, Soma Shirakabe, Yutaka Satoh, Hirokatsu Kataoka, "Human Action Recognition without Human", ECCV 2016 Workshop on Brave New Ideas for Motion Representations in Videos (BNMW), Oct. 2016. (Oral, Brave New Idea) [[PDF]](http://arxiv.org/abs/1608.07876) [[Slide]](http://www.slideshare.net/HirokatsuKataoka/eccv-2016-bnmwhuman-action-recognition-without-human) [[Poster]](http://www.hirokatsukataoka.net/research/withouthuman/ECCV2016_withouthuman_poster.pdf) [[YouTube]](https://www.youtube.com/watch?v=iFsvJXLbgG4)
	* Hirokatsu Kataoka, Yun He, Soma Shirakabe, Yutaka Satoh, "Motion Representation with Acceleration Images", ECCV 2016 Workshop on Brave New Ideas for Motion Representations in Videos (BNMW), Oct. 2016. [[PDF]](http://arxiv.org/abs/1608.08395) [[Poster]](http://www.hirokatsukataoka.net/research/accelerationimages/ECCV2016_acceleration_poster.pdf)
	* Hirokatsu Kataoka, Yudai Miyashita, Masaki Hayashi, Kenji Iwata, Yutaka Satoh, "Recognition of Transitional Action for Short-Term Action Prediction using Discriminative Temporal CNN Feature", British Machine Vision Conference (BMVC), Sep. 2016. (Acceptance rate: 39.4%) [[PDF]](http://www.bmva.org/bmvc/2016/papers/paper012/paper012.pdf) [[Abstract]](http://www.bmva.org/bmvc/2016/papers/paper012/abstract012.pdf) [[Poster]](http://www.hirokatsukataoka.net/research/transitionalactionrecognition/BMVC2016Poster.pdf) [[Slide]](http://www.slideshare.net/HirokatsuKataoka/recognition-of-transitional-action-for-shortterm-action-prediction-using-discriminative-temporal-cnn-feature) [[Video]](https://www.youtube.com/watch?v=m1AmdIYGaBY)
	* Hirokatsu Kataoka, Yudai Miyashita, Tomoaki Yamabe, Soma Shirakabe, Shin'ichi Sato, Hironori Hoshino, Ryo Kato, Kaori Abe, Takaaki Imanari, Naomichi Kobayashi, Shinichiro Morita, Akio Nakamura, "cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey", arXiv pre-print 1605.08247, May. 2016. [[PDF]](http://www.hirokatsukataoka.net/pdf/arxiv16_kataoka_cvpaperchallenge.pdf)
	* Hirokatsu Kataoka, Masaki Hayashi, Kenji Iwata, Yutaka Satoh, Yoshimitsu Aoki, Slobodan Ilic, "Dominant Codewords Selection with Topic Model for Action Recognition", IEEE CVPR 2016 Workshop on ChaLearn Looking at People, Jul. 2016. [[PDF]](http://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w18/papers/Kataokai_Dominant_Codewords_Selection_CVPR_2016_paper.pdf) [[Slide]](http://www.slideshare.net/HirokatsuKataoka/cvpr2016lapdominant-codewords-selection-with-topic-model-for-action-recognition)
	* Hirokatsu Kataoka, Soma Shirakabe, Yudai Miyashita, Akio Nakamura, Kenji Iwata, Yutaka Satoh, "Semantic Change Detection with Hypermaps", arXiv pre-print arXiv:1604.07513, Apr. 2016. [[PDF]](http://arxiv.org/abs/1604.07513)
	* Hirokatsu Kataoka, Yoshimitsu Aoki, Kenji Iwata, Yutaka Satoh, "Activity Prediction Using a Space-Time CNN and Bayesian Framework", 11th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISAPP), Feb. 2016. [[PDF]](http://www.hirokatsukataoka.net/pdf/visapp16_kataoka_prediction.pdf) [[Slide]](http://www.slideshare.net/HirokatsuKataoka/visapp2016activity-prediction-using-a-spacetime-cnn-and-bayesian-framework)

## データセット

* FractalDB [[GitHub]](https://github.com/hirokatsukataoka16/FractalDB-Pretrained-ResNet-PyTorch)
* Fashion Culture Database（FCDB） [[GitHub]](https://github.com/cvpaperchallenge/FashionCultureDataBase_DLoader)
* BoketeDB（非公開）
* Traffic Near-miss Incident Database（NIDB; 非公開）

## 研究グループ

2021年現在の研究グループ。研究メンバーへの参加希望は[こちら](http://xpaperchallenge.org/cv/recruit/)をご確認ください。

* Brave New CV Group（仮）
	* 研究アイディアを考案し、新規に研究グループを創設するためのグループ。

* FATE Group
	* Group Leader: 山田亮佑 [[Scholar]](https://scholar.google.com.au/citations?user=2nmJ6qQAAAAJ&hl=en) [[Twitter]](https://twitter.com/FragileGoodwill)
	* AI/CVのFairness（公平性）, Accountability（説明責任）, Transparency（透明性）, Ethics（倫理）に取り組むグループ。「日本最強のCV in FATEグループを目指す！」を掲げて研究活動を行なっている。
	* 主な成果
		* コンピュータビジョンの観点からみたAIの公平性 [[SSII 2020 招待講演]](https://confit.atlas.jp/guide/event/ssii2020/static/invited_interactive#IS1) [[slide]](https://www.slideshare.net/cvpaperchallenge/ai-229094219)
		* 教師あり事前学習を凌駕する「弱」教師あり事前学習 [[SSII 2020 OS2]](https://confit.atlas.jp/guide/event/ssii2020/static/organized#OS2) [[slide]](https://www.slideshare.net/SSII_Slides/ssii2020-os202-235273375)
		* Weakly Supervised Dataset Collection (arXiv) [[PDF]](https://arxiv.org/abs/2003.12263)
		* Fashion Culture Database (CVPR 2019 WS) [[PDF]](http://openaccess.thecvf.com/content_CVPRW_2019/papers/FFSS-USAD/Kataoka_Ten-Million-Order_Human_Database_for_World-Wide_Fashion_Culture_Analysis_CVPRW_2019_paper.pdf) [[Oral]](http://hirokatsukataoka.net/pdf/cvprw19_kataoka_fcdb_oral.pdf) [[Poster]](http://hirokatsukataoka.net/pdf/cvprw19_kataoka_fcdb_poster.pdf) [[GitHub]](https://github.com/cvpaperchallenge/FashionCultureDataBase_DLoader)

* FDDB Group [[Project Page]](https://hirokatsukataoka16.github.io/Formula-Driven-DataBase-Group/)
	* Group Leader: 片岡裕雄 [[HP]](http://hirokatsukataoka.net/) [[Scholar]](https://scholar.google.com.au/citations?user=f1CePVQAAAAJ&hl=en) [[Twitter]](https://twitter.com/hirokatukataoka) [[GitHub]](https://github.com/hirokatsukataoka16) [[YouTube]](https://www.youtube.com/channel/UCieS-nGsYW2hdj2SSG3MDnA)
	* Formula-Driven DataBaseでFDDB Group。画像パターンおよび画像カテゴリを自動で生成して大規模事前学習データセットを生成する数式ドリブン教師あり学習を研究。その他、自己教師学習などの学習戦略についても検討を行う。
	* 主な成果
		* 科研費基盤研究(A)獲得 [[Link]](https://kaken.nii.ac.jp/grant/KAKENHI-PROJECT-19H01134/)
		* Pre-training without Natural Images (ACCV 2020 Best Paper Honorable Mention Award) [[Project]](https://hirokatsukataoka16.github.io/Pretraining-without-Natural-Images/) [[PDF]](https://openaccess.thecvf.com/content/ACCV2020/papers/Kataoka_Pre-training_without_Natural_Images_ACCV_2020_paper.pdf) [[Code]](https://github.com/hirokatsukataoka16/FractalDB) [[Dataset]](https://hirokatsukataoka16.github.io/Pretraining-without-Natural-Images/#dataset) [[Oral]](http://hirokatsukataoka.net/pdf/accv20_kataoka_oral.pdf) [[Poster]](http://hirokatsukataoka.net/pdf/accv20_kataoka_poster.pdf) [[Video]](https://www.youtube.com/watch?v=d-NagM4nGIQ)
		* Multi-View FractalDB（ViEW 2020 小田原賞）[[Twitter]](https://twitter.com/CVpaperChalleng/status/1333960272252264448)
		* FDDB 特性評価（SSII 2020 オーディエンス賞次点）

* GAN Fighters Group
	* Group Leader: 綱島秀樹 [[Scholar]](https://scholar.google.com/citations?user=ZZvzcpAAAAAJ&hl=ja) [[Twitter]](https://twitter.com/maguroIsland)
	* GAN, Image-to-Imageなど生成モデルについて研究を行う。研究的にも物理的にも強いメンバーが多い？
	* 主な成果
		* Viewpoint-agnostic Image Rendering (WACV 2021) [[Project]](https://aizawan.github.io/vair/) [[PDF]](https://openaccess.thecvf.com/content/WACV2021/html/Aizawa_Viewpoint-Agnostic_Image_Rendering_WACV_2021_paper.html)
		* Augmented Cyclic Consistency Regularization (ICPR 2020) [[PDF]](https://arxiv.org/abs/2003.00187)
		* Adversarial Knowledge Distillation for a Compact Generator (ICPR 2020)
		* Disentangle, Assemble, and Synthesize (ICPR 2020) [[Project]](https://aizawan.github.io/das/)

* Interaction Group
	* Group Leader: 鈴木亮太 [[GitHub]](https://github.com/suzuryo3893)
	* CVxHCI、効率的アノテーション、CVアプリケーションについて取り組む研究グループ。
	* 主な成果
		* ImageNet Re-annotation [[Twitter]](https://twitter.com/CVpaperChalleng/status/1290215730395246593)

* V&L Group
	* Group Leader: 山本晋太郎 [[HP]](https://yamashin42.github.io/yamashin42/) [[Scholar]](https://scholar.google.com/citations?user=l0MfuXwAAAAJ&hl=ja) [[Twitter]](https://twitter.com/yshin55)
	* Vision & Languageに取り組むグループ。
	* 主な成果
		* 3D-Aware Scene Change Captioning (RA-L w/ IROS 2020)
		* Incorporating Depth into VQA (CVPR 2019 WS)

* VideoRecog Group
	* Group Leader: 原健翔 [[HP]](https://kenshohara.github.io/index.html) [[Scholar]](https://scholar.google.co.jp/citations?user=sjLJqcYAAAAJ&hl=ja) [[GitHub]](https://github.com/kenshohara)
	* 動画認識に取り組むグループ
	* 主な成果
		* 3D ResNet (CVPR 2018) [[PDF]](https://arxiv.org/abs/1711.09577v2) [[Poster]](http://hirokatsukataoka.net/research/3dconv/cvpr18_3dconv_poster.pdf) [GitHub](https://github.com/kenshohara/3D-ResNets-PyTorch)
		* Anticipating Traffic Accidents (CVPR 2018) [[PDF]](https://arxiv.org/abs/1804.02675) [[Poster]](http://hirokatsukataoka.net/research/nidb/cvpr18_anticipation_poster.pdf)
		* Out-of-context Action Understanding (ICRA 2019)
		* Traffic Near-miss DataBase (ICRA 2018) [[PDF]](https://arxiv.org/abs/1804.02555) [[Poster]](http://hirokatsukataoka.net/research/nidb/icra18_kataoka_nidb_poster.pdf) [[Digest]](http://hirokatsukataoka.net/research/nidb/icra18_kataoka_nidb_digest.pdf)
		* Human Action Recognition without Human (ECCV 2016 WS; Brave New Idea) [[PDF]](http://arxiv.org/abs/1608.07876) [[Slide]](http://www.slideshare.net/HirokatsuKataoka/eccv-2016-bnmwhuman-action-recognition-without-human) [[Poster]](http://www.hirokatsukataoka.net/research/withouthuman/ECCV2016_withouthuman_poster.pdf) [[YouTube]](https://www.youtube.com/watch?v=iFsvJXLbgG4)
		* Transitional Action Recognition (BMVC 2016) [[PDF]](http://www.bmva.org/bmvc/2016/papers/paper012/paper012.pdf) [[Abstract]](http://www.bmva.org/bmvc/2016/papers/paper012/abstract012.pdf) [[Poster]](http://www.hirokatsukataoka.net/research/transitionalactionrecognition/BMVC2016Poster.pdf) [[Slide]](http://www.slideshare.net/HirokatsuKataoka/recognition-of-transitional-action-for-shortterm-action-prediction-using-discriminative-temporal-cnn-feature) [[Video]](https://www.youtube.com/watch?v=m1AmdIYGaBY)

## 網羅的サーベイ

* ECCV 2020 網羅的サーベイ [[論文サマリ]](http://xpaperchallenge.org/cv/survey/eccv2020_summaries/listall/) [[オーラル完全読破]](https://docs.google.com/presentation/d/1o8254nerFD1MBFGmOY-MEp5Es4ymp6UWuXDZYEee5yo/edit#slide=id.g9857377513_2_9) [[オーラル完全読破 Slideshare 1]](https://www.slideshare.net/cvpaperchallenge/eccv2020-oral-12/1) [[オーラル完全読破 Slideshare 2]](https://www.slideshare.net/cvpaperchallenge/eccv2020-22-238640597/1)
* CVPR 2020 網羅的サーベイ [[論文サマリ]](http://xpaperchallenge.org/cv/survey/cvpr2020_summaries/listall/)
* ICCV 2019 網羅的サーベイ[[論文サマリ]](http://xpaperchallenge.org/cv/survey/iccv2019_summaries/listall/)
* CVPR 2019 網羅的サーベイ [[論文サマリ]](http://xpaperchallenge.org/cv/survey/cvpr2019_summaries/listall/) [[報告会]](https://cvpr2019-survey.studio.site/)
* ECCV 2018 網羅的サーベイ [[論文サマリ]](https://github.com/cvpaperchallenge/ECCV2018_Survey/blob/master/ECCV2018_Survey.md)
* CVPR 2018 完全読破チャレンジ [[論文サマリ]](https://cvpaperchallenge.github.io/CVPR2018_Survey/#/%5D) [[HP]](http://hirokatsukataoka.net/project/cc/cvpr2018survey.html) [[GitHub]](https://github.com/cvpaperchallenge/CVPR2018_Survey) [[Blog]](http://hirokatsu16.blog.fc2.com/blog-entry-113.html)
* 2016年 年間1,000本チャレンジ [[2016年1月(1/3)]](https://www.slideshare.net/cvpaperchallenge/20160113cvpaperchallenge2016-59173880) [[2016年1月(2/3)]](https://www.slideshare.net/cvpaperchallenge/20160123cvpaperchallenge2016) [[2016年1月(3/3)]](https://www.slideshare.net/cvpaperchallenge/20160133cvpaperchallenge2016) [[2016年2月]](https://www.slideshare.net/cvpaperchallenge/201602cvpaperchallenge2016) [[2016年3月]](https://www.slideshare.net/cvpaperchallenge/201603cvpaperchallenge2016-60794932) [[2016年4月]](https://www.slideshare.net/cvpaperchallenge/201604cvpaperchallenge2016-62916842) [[2016年5月]](https://www.slideshare.net/cvpaperchallenge/201605cvpaperchallenge2016) [[2016年6月]](https://www.slideshare.net/cvpaperchallenge/201606cvpaperchallenge2016) [[2016年7月]](https://www.slideshare.net/cvpaperchallenge/201607cvpaperchallenge2016) [[2016年8月]](https://www.slideshare.net/cvpaperchallenge/201608cvpaperchallenge2016) [[2016年9月]](https://www.slideshare.net/cvpaperchallenge/201609cvpaperchallenge2016) [[2016年10月]](https://www.slideshare.net/cvpaperchallenge/201610cvpaperchallenge2016) [[2016年11月]](https://www.slideshare.net/cvpaperchallenge/201611cvpaperchallenge2016) [[2016年12月]](https://www.slideshare.net/cvpaperchallenge/201612cvpaperchallenge2016) 
* CVPR 2015 完全読破チャレンジ [[2015年05月]](https://www.slideshare.net/cvpaperchallenge/201505-cvpaperchallenge) [[2015年6月]](https://www.slideshare.net/cvpaperchallenge/201506-cvpaperchallenge) [[2015年7月(1/2)]](https://www.slideshare.net/cvpaperchallenge/201507-cvpaperchallenge1) [[2015年7月(2/2)]](https://www.slideshare.net/cvpaperchallenge/20150722cvpaperchallengecvpr2015) [[2015年8月(1/5)]](https://www.slideshare.net/cvpaperchallenge/20150815cvpaperchallengecvpr2015) [[2015年8月(2/5)]](https://www.slideshare.net/cvpaperchallenge/20150825cvpaperchallengecvpr2015) [[2015年8月(3/5)]](https://www.slideshare.net/cvpaperchallenge/20150835cvpaperchallengecvpr2015) [[2015年8月(4/5)]](https://www.slideshare.net/cvpaperchallenge/20150845cvpaperchallengecvpr2015) [[2015年8月(5/5)]](https://www.slideshare.net/cvpaperchallenge/20150855cvpaperchallengecvpr2015) 



## メタサーベイ 

* 2020
	* 自己教師学習 [[slide]](https://www.slideshare.net/cvpaperchallenge/selfsupervised-learning-232896551)
	* コンピュータビジョンの観点から見たAIの公平性 [[slide]](https://www.slideshare.net/cvpaperchallenge/ai-229094219)
	* Adversarial Examples分野の動向 [[slide]](https://www.slideshare.net/cvpaperchallenge/adversarial-examples-229232499)
	* Performance is not all you need -CV分野における論文への要求- [[slide]](https://www.slideshare.net/cvpaperchallenge/performance-is-not-all-you-need-cv)
	* Generative Models [[slide]](https://www.slideshare.net/cvpaperchallenge/generative-models-233089430)
	* Towards Performant Video Recognition [[slide]](https://www.slideshare.net/cvpaperchallenge/towards-performant-video-recognition-231628214)
	* 動画認識 [[slide]](https://www.slideshare.net/cvpaperchallenge/v1-232973484)
	* Geotag Data Mining [[slide]](https://www.slideshare.net/cvpaperchallenge/geotag-data-mining)
	* Vision and Language [[slide]](https://www.slideshare.net/cvpaperchallenge/vision-and-language-232926110)
	* Rethinking and Beyond ImageNet [[slide]](https://www.slideshare.net/cvpaperchallenge/rethinking-and-beyond-imagenet)
	* CVPR 2020
		* 3D From a Single Image and Shape-From-X [[slide]](https://www.slideshare.net/cvpaperchallenge/3d-from-a-single-image-and-shapefromx)
		* Action and Behavior Recognition [[slide]](https://www.slideshare.net/cvpaperchallenge/action-and-behavior-recognition-237135153)
		* Adversarial Learning [[slide]](https://www.slideshare.net/cvpaperchallenge/adversarial-learning)
		* 3D From Multiview and Sensors [[slide]](https://www.slideshare.net/cvpaperchallenge/3d-from-multiview-and-sensors)
		* Computational Photography [[slide]](https://www.slideshare.net/cvpaperchallenge/computational-photography-237175059)
		* Efficient Training and Inference Methods for Networks [[slide]](https://www.slideshare.net/cvpaperchallenge/efficient-training-and-inference-methods-for-networks-237146257)
		* Image Retrieval [[slide]](https://www.slideshare.net/cvpaperchallenge/image-retrieval-237138266)
		* Datasets and Evaluation [[slide]](https://www.slideshare.net/cvpaperchallenge/datasets-and-evaluation)
		* Scene Analysis and Understanding [[slide]](https://www.slideshare.net/cvpaperchallenge/scene-analysis-and-understanding)
		* Medical, Biological and Cell Microscopy [[slide]](https://www.slideshare.net/cvpaperchallenge/cvpr-2020-medical-biological-and-cell-microscopy)
		* Transfer/Low-Shot/Semi/Unsupervised Learning [[slide]](https://www.slideshare.net/cvpaperchallenge/cvpr-2020-transferlowshotsemiunsupervised-learning)
		* Face, Gesture, and Body Pose [[slide]](https://www.slideshare.net/cvpaperchallenge/face-gesture-and-body-pose)
		* Image and Video Synthesis [[slide1]](https://www.slideshare.net/cvpaperchallenge/cvpr-2020-image-and-video-synthesisgroup141) [[slide2]](https://www.slideshare.net/cvpaperchallenge/cvpr-2020-image-and-video-synthesisgroup142)
		* Representation Learning [[slide]](https://www.slideshare.net/cvpaperchallenge/representation-learning-237163481)
		* Neural Generative Models [[slide]](https://www.slideshare.net/cvpaperchallenge/neural-generative-models)
		* Explainable AI; Fairness, Accountability, Transparency and Ethics in Vision [[slide]](https://www.slideshare.net/cvpaperchallenge/explainable-ai-fairness-accountability-transparency-and-ethics-in-vision)
		* Recognition (Detection, Categorization) [[slide1]](https://www.slideshare.net/cvpaperchallenge/recognition-detection-categorization) [[slide2]](https://www.slideshare.net/cvpaperchallenge/recognition-detection-categorizationgroup212)
		* Video Analysis and Understanding [[slide]](https://www.slideshare.net/cvpaperchallenge/video-analysis-and-understanding)
		* Vision & Language [[slide]](https://www.slideshare.net/cvpaperchallenge/cvpr-2020-vision-language)
		* Machine Learning Architectures and Formulations [[slide]](https://www.slideshare.net/cvpaperchallenge/cvpr-2020-machine-learning-architectures-and-formulations)
		* Vision Applications and Systems [[slide]](https://www.slideshare.net/cvpaperchallenge/vision-applications-and-systems-237164035)
		* Vision & Other Modalities [[slide]](https://www.slideshare.net/cvpaperchallenge/cvpr-2020-vision-other-modalities)
		* Visual Reasoning and Logical Representation [[slide]](https://www.slideshare.net/cvpaperchallenge/visual-reasoning-and-logical-representation)
* 2019
	* 敵対的生成ネットワーク（GAN） [[slide]](https://www.slideshare.net/cvpaperchallenge/gan-133159239)
	* 物体検知 [[slide]](https://www.slideshare.net/cvpaperchallenge/meta-study-group)
	* 点群深層学習 [[slide]](https://www.slideshare.net/naoyachiba18/metastudy)
	* ML基盤 [[slide]](https://www.slideshare.net/OtaOtaku/ml-cvpaperchallenge-metastudygroup20190315)
	* Vision and Language [[slide]](https://www.slideshare.net/ShintaroYamamoto1/vision-and-language)
	* Generative Adversarial Networks and Actor-Critic Methods [[slide]](https://www.slideshare.net/takehiko-ohkawa/generative-adversarial-networks-and-actorcritic-methods)
	* 超解像 [[slide]](https://www.slideshare.net/S_aiueo32/cvpaperchallenge-metastudygroup)

## 会議レポート

* CVPR 2020 報告 [[Link]](https://www.slideshare.net/cvpaperchallenge/cvpr-2020-237139930)
* ICRA 2020 速報 [[Link1]](https://www.slideshare.net/robotpaperchallenge/icra2020-v1-236388919) [[Link2]](https://www.slideshare.net/robotpaperchallenge/icra2020-v2-236380702)
* CVPR 2019 速報 [[Link]](https://www.slideshare.net/cvpaperchallenge/cvpr-2019)
* ICRA 2019 速報 [[Link]](https://www.slideshare.net/cvpaperchallenge/icra-2019)
* CVPR 2018 速報 [[Link]](https://www.slideshare.net/cvpaperchallenge/cvpr-2018-102878612) [[中国語版]](https://www.slideshare.net/cvpaperchallenge/cvpr-2018-108829446) [[更新版]](https://www.slideshare.net/cvpaperchallenge/cvpr-2018-cvpr-2018)
* ICRA 2018 速報 [[Link]](https://www.slideshare.net/cvpaperchallenge/icra-2018)
* ICCV 2017 速報 [[Link]](https://www.slideshare.net/cvpaperchallenge/iccv-2017)
* CVPR 2017 速報 [[Link]](https://www.slideshare.net/cvpaperchallenge/cvpr-2017-78294211)
* ECCV 2016 速報 [[Link]](https://www.slideshare.net/HirokatsuKataoka/eccv-2016)
* CVPR 2016 速報 [[Link]](https://www.slideshare.net/HirokatsuKataoka/cvpr-2016)

## 招待講演

* Adversarial Examples 研究動向（SSII 2020 招待インタラクティブ発表） [[HP]](https://confit.atlas.jp/guide/event/ssii2020/static/invited_interactive#IS2) [[slide]](https://www.slideshare.net/cvpaperchallenge/adversarial-examples-229232499)
* コンピュータビジョンの観点からみたAIの公平性（SSII 2020 招待インタラクティブ発表） [[HP]](https://confit.atlas.jp/guide/event/ssii2020/static/invited_interactive#IS1) [[slide]](https://www.slideshare.net/cvpaperchallenge/ai-229094219)
* CV分野の今を映すcvpaper.challengeの取り組み（SSII 2018 招待インタラクティブ発表 2018年6月） [[HP]](https://confit.atlas.jp/guide/event/ssii2018/static/invited_interactive) [[poster]](http://hirokatsukataoka.net/temp/cvpaper.challenge/ssii2018_poster.pdf)
* CVPR 2018 速報とその後（CVPR 2018 完全読破チャレンジ報告会 2018年9月）[[slide]](https://www.slideshare.net/cvpaperchallenge/cvpr-2018-cvpr-2018)
* GANsの最新動向: 応用領域でのGANs (CVPR 2018 完全読破チャレンジ報告会 2018年9月) [[slide]](https://www.slideshare.net/cvpaperchallenge/gans-gans-cvpr-2018) 
* 顔認識の未来について語ろう！ (CVPR 2018 完全読破チャレンジ報告会 2018年9月) [[slide]](https://www.slideshare.net/cvpaperchallenge/cvpr-2018-117324818)
* Neural Joking Machine: Humorous Image Captioning (CVPR 2018 完全読破チャレンジ報告会 2018年9月) [[slide]](https://www.slideshare.net/cvpaperchallenge/verneural-joking-machine-humorous-image-captioning-cvpr-2018)
* Visual Question Answering (VQA) - CVPR2018動向分析 (CVPR 2018 完全読破チャレンジ報告会 2018年9月) [[slide]](https://www.slideshare.net/cvpaperchallenge/visual-question-answering-vqa-cvpr2018-cvpr-2018)
* 教師なし画像特徴表現学習の動向 {Un, Self} supervised representation learning (CVPR 2018 完全読破チャレンジ報告会 2018年9月) [[slide]](https://www.slideshare.net/cvpaperchallenge/un-self-supervised-representation-learning-cvpr-2018)
* 動画認識・キャプショニングの潮流 (CVPR 2018 完全読破チャレンジ報告会) [[slide]](https://www.slideshare.net/cvpaperchallenge/cvpr-2018-117261477)
* 優れた問いを見つける（中京大学講演 2017年2月） [[slide]](https://www.slideshare.net/cvpaperchallenge/ss-72641629) 
* これからのコンピュータビジョン技術 - cvpaper.challenge in PRMU Grand Challenge 2016（PRMU研究会 2016年12月） [[slide]](https://www.slideshare.net/cvpaperchallenge/cvpaperchallenge-in-prmu-grand-challenge-2016-prmu-201612)
* cvpaper.challenge -CVの動向とこれからの問題を作るために-（東京大学講演 2016年9月） [[slide]](https://www.slideshare.net/cvpaperchallenge/cvpaperchallenge-cv)
* cvpaper.challenge -サーベイの共有と可能性について-（画像応用技術専門委員会研究会 2016年7月）[[slide]](https://www.slideshare.net/cvpaperchallenge/cvpaperchallenge-20167-64272647)
* cvpaper.challenge in CVPR 2015（PRMU2015年12月） [[slide]](https://www.slideshare.net/cvpaperchallenge/cvpaperchallenge-in-cvpr2015-prmu201512-56326765)


## 記事

* 論文を読むこととは、cvpaper.challengeが見据える先は（AI-SCHOLAR 2020年11月18日）[[Link]](https://ai-scholar.tech/articles/interview/cvpaper.challenge0)
* 網羅的サーベイから見るAI論文とは ラスト！！（AI-SCHOLAR 2020年9月7日）[[Link]](https://ai-scholar.tech/articles/interview/CVPR2020_survey6)
* 網羅的サーベイから見るAI論文とは Part4（AI-SCHOLAR 2020年8月12日）[[Link]](https://ai-scholar.tech/articles/interview/CVPR2020_survey2)
* 網羅的サーベイから見るAI論文とは Part3（AI-SCHOLAR 2020年8月11日）[[Link]](https://ai-scholar.tech/articles/interview/CVPR2020_survey4)
* 網羅的サーベイから見るAI論文とは Part2（AI-SCHOLAR 2020年8月6日）[[Link]](https://ai-scholar.tech/articles/interview/CVPR2020_survey3)
* 網羅的サーベイから見るAI論文とは Part1（AI-SCHOLAR 2020年8月4日）[[Link]](https://ai-scholar.tech/articles/interview/CVPR2020_survey1)
* CVPR2019に参加して感じた、CV分野のトレンドと気づき Part 1（logmi（ログミー） 2019年8月27日） [[Link]](https://logmi.jp/tech/articles/321775)
* CVPR2019に参加して感じた、CV分野のトレンドと気づき Part 2（logmi（ログミー） 2019年8月28日） [[Link]](https://logmi.jp/tech/articles/321778)

## その他

* ブレインストーミング法 [[slide]](https://www.slideshare.net/cvpaperchallenge/xpaperchallenge)
* 2017年の研究戦略 [[slide]](https://www.slideshare.net/cvpaperchallenge/2017-cvpaperchallenge-2017)
* cvpaper.challengeについて [[slide]](https://www.slideshare.net/cvpaperchallenge/cvpaperchallenge)

